{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 30.01.2025\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 16.02.2025\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 23.02.2025\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "Использование генеративных языковых моделей разрешено только в случае явного указания на это. Необходимо прописать (в соответствующих пунктах, где использовались, либо в начале/конце работы):\n",
    "- какая языковая модель использовалась\n",
    "- какие использовались промпты и в каких частях работы\n",
    "- с какими сложностями вы столкнулись при использовании генеративных моделей, с чем они помогли больше всего\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1 Способ \n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 2 Способ (если первый не работает)\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# def load_fashion_mnist():\n",
    "#     X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n",
    "#     X = X.reshape(-1, 28, 28).astype('uint8')\n",
    "#     y = y.astype('int64')\n",
    "#     x_train, x_test = X[:60000], X[60000:]\n",
    "#     y_train, y_test = y[:60000], y[60000:]\n",
    "#     return (x_train, y_train), (x_test, y_test)\n",
    "# (x_train_pics, y_train), (x_test_pics, y_test) = load_fashion_mnist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 0. (0.25 баллов)__\n",
    "\n",
    "**Вопрос:** зачем в алгоритме нужен метод главных компонент? \n",
    "\n",
    "**Ответ:** Для rff нужно большое количество скалярных произведений. А наши данные имеют размерность 784. Следовательно для оптимизации работы нам нужно снизить размерность, что и делает МГК. Также он позволяет убрать избыточные признаки, что позволяет улучшить приближение ядра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (3 балла)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса в `homework_practice_08_rff.py` (допишите его и исправьте несостыковки в классе пайплайна) или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jP8yepx8K-hT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy: 0.8721\n",
      "CPU times: user 1min 31s, sys: 5.47 s, total: 1min 36s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from homework_practice_08_rff import RFFPipeline, RandomFeatureCreator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = RFFPipeline(n_features=1000, new_dim=50, classifier_class=LogisticRegression, feature_creator_class=RandomFeatureCreator)\n",
    "pipeline.fit(x_train,y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "print(\"logreg accuracy:\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy: 0.8783\n",
      "CPU times: user 9min 7s, sys: 5.07 s, total: 9min 13s\n",
      "Wall time: 9min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "pipeline_svm = RFFPipeline(n_features=1000, new_dim=50, classifier_class=SVC, feature_creator_class=RandomFeatureCreator)\n",
    "pipeline_svm.fit(x_train, y_train)\n",
    "y_pred = pipeline_svm.predict(x_test)\n",
    "print(\"svm accuracy:\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (2.5 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучите градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost. \n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qN8LUlJgK-hV",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py:317\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[1;32m    313\u001b[0m _dual \u001b[38;5;241m=\u001b[39m _validate_dual_parameter(\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, X\n\u001b[1;32m    315\u001b[0m )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# and LogisticRegression but LogisticRegression sets a structured\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# `n_iter_` attribute with information about the underlying OvR fits\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# while LinearSVC/R only reports the maximum value.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m n_iter_\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1215\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1212\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1214\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[0;32m-> 1215\u001b[0m raw_coef_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mliblinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m n_iter_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Linear_SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "svm_classifier = LinearSVC(max_iter=10000, dual = 'auto')\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "y_pred = svm_classifier.predict(x_test)\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я случайно запустил клетку перед отправкой дз, а она долго исполняется(. Но результат до этого был че-то типо 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8828\n",
      "CPU times: user 6min 58s, sys: 2.09 s, total: 7min\n",
      "Wall time: 7min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Kernel_SVC\n",
    "svm_classifier = SVC(max_iter=10000, kernel = 'rbf')\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "y_pred = svm_classifier.predict(x_test)\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейный svm работает сильно дольше, а качество при этом хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 19:30:25,935] A new study created in memory with name: no-name-cf18a26e-c262-4655-9252-3895a31b2324\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 19:35:17,602] Trial 0 finished with value: 0.5451 and parameters: {'subsample': 0.9331616935017512, 'eta': 0.20202822846920207, 'gamma': 1.2478144188721652, 'max_depth': 8, 'n_estimators': 115}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 19:40:20,386] Trial 1 finished with value: 0.5451 and parameters: {'subsample': 0.5702419274576634, 'eta': 0.015693763832350008, 'gamma': 5.747435292147356, 'max_depth': 3, 'n_estimators': 32}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 19:45:07,425] Trial 2 finished with value: 0.5451 and parameters: {'subsample': 0.4513389043289205, 'eta': 0.8240196455664792, 'gamma': 6.644055388655634, 'max_depth': 5, 'n_estimators': 95}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 19:50:06,335] Trial 3 finished with value: 0.5451 and parameters: {'subsample': 0.991485658248493, 'eta': 0.4828101657278103, 'gamma': 0.08888348730966, 'max_depth': 4, 'n_estimators': 60}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 19:59:40,720] Trial 4 finished with value: 0.5451 and parameters: {'subsample': 0.7383168129379625, 'eta': 0.903104406533464, 'gamma': 0.47340208882756807, 'max_depth': 5, 'n_estimators': 167}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 20:08:01,665] Trial 5 finished with value: 0.5451 and parameters: {'subsample': 0.7300986468790429, 'eta': 0.765403822457098, 'gamma': 7.544423144894444, 'max_depth': 8, 'n_estimators': 85}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 20:16:25,263] Trial 6 finished with value: 0.5451 and parameters: {'subsample': 0.5451895611147582, 'eta': 0.8172059723742988, 'gamma': 0.0050920679756016884, 'max_depth': 5, 'n_estimators': 47}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 20:25:28,973] Trial 7 finished with value: 0.5451 and parameters: {'subsample': 0.593209694335888, 'eta': 0.38317774635049573, 'gamma': 5.376912771545345, 'max_depth': 1, 'n_estimators': 12}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 20:34:07,804] Trial 8 finished with value: 0.5451 and parameters: {'subsample': 0.7796877858484794, 'eta': 0.5369563240924458, 'gamma': 1.505658282584661, 'max_depth': 1, 'n_estimators': 144}. Best is trial 0 with value: 0.5451.\n",
      "/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[I 2025-02-23 20:43:13,824] Trial 9 finished with value: 0.5451 and parameters: {'subsample': 0.4444435152359599, 'eta': 0.9531770824017093, 'gamma': 0.8700938296089933, 'max_depth': 7, 'n_estimators': 115}. Best is trial 0 with value: 0.5451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5451\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(50)\n",
    "x_train_pca = pca.fit_transform(x_train)\n",
    "x_test_pca = pca.fit_transform(x_test)\n",
    "def opt(trial):\n",
    "    params = {\n",
    "        'subsample' : trial.suggest_float('subsample', 0.001, 1),\n",
    "        'learning_rate' : trial.suggest_float('eta', 0.001, 1),\n",
    "        'gamma' : trial.suggest_float('gamma', 0, 10),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 1, 10),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 1, 200)}\n",
    "    model = xgb.XGBClassifier(params, objective='multi:softprob')\n",
    "\n",
    "    model.fit(x_train_pca, y_train)\n",
    "    return accuracy_score(y_test, model.predict(x_test_pca))\n",
    "\n",
    "\n",
    "boosting = optuna.create_study(direction='maximize')\n",
    "boosting.optimize(opt, n_trials=10)\n",
    "\n",
    "score = boosting.best_value\n",
    "print(\"accuracy:\", boosting.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг работал долго и дал результаты значительно хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.1003\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "no_pca = RFFPipeline(classifier_class=LogisticRegression, use_PCA=False)\n",
    "no_pca.fit(x_train, y_train)\n",
    "y_pred = no_pca.predict(x_test)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "без PCA качество как у рандома"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████▋                                       | 1/8 [00:05<00:36,  5.26s/it]/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 25%|███████████▎                                 | 2/8 [00:11<00:35,  5.94s/it]/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 38%|████████████████▉                            | 3/8 [00:19<00:33,  6.69s/it]/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 50%|██████████████████████▌                      | 4/8 [00:29<00:31,  7.98s/it]/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 62%|████████████████████████████▏                | 5/8 [00:44<00:31, 10.63s/it]/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 75%|█████████████████████████████████▊           | 6/8 [02:08<01:11, 35.66s/it]/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [03:16<00:45, 45.99s/it]/Users/ilushka/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|█████████████████████████████████████████████| 8/8 [06:16<00:00, 47.04s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_features_list = [10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "scores = []\n",
    "for n_features in tqdm(n_features_list):\n",
    "    pipeline = RFFPipeline(classifier_class=LogisticRegression, use_PCA=True, n_features=n_features)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.plot(n_features_list, scores)\n",
    "plt.axhline(scores[-1], color = 'red', linestyle = '--')\n",
    "plt.title('Dependence Accuracy on n_features')\n",
    "plt.xlabel('n_features')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как мы видим в увеличении количества признаков с приблизительно n_features=1000 нет смысла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 (проводил выше в задании 1 для проверки кода)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "у SVM accuracy оказалался немного выше, но не значительно. Поэтому не так важно какую модель обучать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 1.5 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет), n_features=new_dim и n_features < new_dim также должны работать, убедитесь в этом. Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 1 балл)__\n",
    "\n",
    "Существует большое количество работ, где идея RFF развивается, предлагаются её обобщения (которые, по сути, выливаются в другие преобразования признаков, не обязательно уже тригонометрические). Возьмите любую из таких работ, кратко опишите идею, имплементируйте её и сравните качество с ORF и RFF, которые вы запрограммировали выше.\n",
    "\n",
    "Ссылки на статьи, где обсуждаются вариации RFF для разных ядер, можно найти в окрестности таблицы 1 в работе https://arxiv.org/pdf/1407.5599  \n",
    "\n",
    "___ссылка на работу:___\n",
    "\n",
    "___описание идеи:___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "# Пример "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6. (Максимум 2.5 балла)__\n",
    "\n",
    "Реализуйте класс ядровой Ridge регрессии (Лекция 13, $\\S 1.2$), для оптимизации используте градиентный спуск **[1 балл максимум]**, также добавьте возможность использовать аналитическую формулу **[1 балл максимум]**. Для градиентного спуска выпишите градиент ниже **[0.5 баллов максимум]**. \n",
    "Подумайте о том, как в формулах правильно учесть свободный коэффициент. \n",
    "\n",
    "Затем адаптируйте вашу реализацию RFF под задачу регрессии. Сравните вашу ядровую регрессию и RFF на синтетических данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь: \n",
    "$$\n",
    "Q(w) = \\frac{1}{2} ||\\Phi \\Phi^T w - y||^2 + \\frac{\\lambda}{2} w^T \\Phi \\Phi^T w \\rightarrow \\min_w,\n",
    "$$\n",
    "где $\\Phi \\Phi^T = K$, $K = (k(x_i, x_j))_{i, j = 1}^{\\ell}$.\n",
    "\n",
    "Предсказание: \n",
    "$\n",
    "y(x) = k(x)^T w,\n",
    "$\n",
    "где $k(x)$ — вектор функций ядра от пар объектов $(x, x_i)_{i=1}^{\\ell}$.\n",
    "\n",
    "___Выведите градиент:___ \n",
    "$$\n",
    "\\nabla ...\n",
    "$$\n",
    "\n",
    "Вы можете изменять представленный шаблон в файле `homework_practice_08_kernel_regression.py` по своему усмотрению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homework_practice_08_kernel_regression import KernelRidgeRegression"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
